# ğŸ¤– RAG Chatbot with Multi-PDF Support using Streamlit + Groq (LLaMA3)

This project is a fully interactive **RAG (Retrieval-Augmented Generation) Chatbot** built with **Streamlit** and **LangChain**, powered by **Groq's blazing-fast LLaMA3-8B**. It allows you to upload **multiple PDFs**, ask questions, and get precise, context-aware answers in a conversational format.

---

## ğŸš€ Features

- ğŸ“¤ Upload **multiple PDF documents**
- ğŸ¤– LLM-powered answers via **Groq LLaMA3-8B**
- ğŸ“‘ **Document viewer** in sidebar (first 3 pages per PDF)
- ğŸ”„ **Loading spinner** while processing queries
- ğŸ’¬ Chat-style history and interface
- ğŸ§  Uses **HuggingFace sentence-transformers** for embeddings

---

## ğŸ“¸ Demo

> Upload PDFs â†’ Ask Questions â†’ Get Context-Aware Answers

![Screenshot 2025-06-17 225618](https://github.com/user-attachments/assets/dc83f75a-465b-40b8-bf8a-9f322f3f1d03)


---

## ğŸ§± Tech Stack

| Layer        | Tool/Library                      |
|--------------|-----------------------------------|
| UI           | [Streamlit](https://streamlit.io) |
| Backend      | [LangChain](https://www.langchain.com) |
| LLM Host     | [Groq](https://console.groq.com/) (LLaMA3) |
| Embeddings   | `sentence-transformers/all-MiniLM-L6-v2` |
| PDF Handling | PyPDF2, LangChain PDF Loader      |

---
---
## ğŸ—‚ï¸ Project Structure
rag_chatbot/
â”œâ”€â”€ app.py # Streamlit frontend
â”œâ”€â”€ rag_engine.py # Core RAG logic (PDF loading, LLM response)
â”œâ”€â”€ .env # API key for Groq
â”œâ”€â”€ temp/ # Temporary file storage
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
---



---

## âš™ï¸ Setup Instructions

### âœ… Step 1: Clone the Repository

```bash
git clone https://github.com/your-username/rag-chatbot.git
cd rag-chatbot

### âœ… Step 2: Create Virtual Environment
python -m venv venv
# Activate it
source venv/bin/activate       # On Linux/Mac
venv\Scripts\activate          # On Windows

### âœ… Step 3: Install Dependencies
pip install -r requirements.txt

### requirements.txt
streamlit
python-dotenv
langchain
langchain-community
langchain-core
langchain-groq
PyPDF2
sentence-transformers

### âœ… Step 4: Set Environment Variables
GROQ_API_KEY=your_actual_groq_api_key

### â–¶ï¸ Run the Application
streamlit run app.py

## ğŸ’¡ How It Works

- PDF files are uploaded and stored temporarily in a `/temp/` directory.
- Text is extracted using `PyPDF2` and `LangChain`â€™s `PyPDFLoader`.
- Text chunks are embedded using `HuggingFace` sentence-transformers (`all-MiniLM-L6-v2`).
- A vectorstore is created and queried via `LangChain's RetrievalQA`.
- User queries are answered using `Groqâ€™s LLaMA3-8B` model, delivering fast and accurate responses grounded in the uploaded content.

---

## âœ¨ Future Enhancements

- [ ] Source highlighting in answers
- [ ] Export chat to PDF/Markdown
- [ ] Upload `.docx` / `.txt` files
- [ ] Switchable LLMs (OpenAI, Claude, Mixtral)

---

## ğŸ™ Acknowledgments

- [LangChain](https://www.langchain.com)
- [Groq](https://console.groq.com)
- [Streamlit](https://streamlit.io)
- [HuggingFace](https://huggingface.co)

---

## ğŸ“œ License

This project is licensed under the [MIT License](LICENSE).

---

## ğŸ§  Author

**Vaibhav Anand**  
Feel free to reach out or contribute!


